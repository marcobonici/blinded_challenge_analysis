{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Japanese simulations analysis\n",
    "\n",
    "In this notebook, we are going to analyze the datasets coming from the japanese simulations of Nishimichi.\n",
    "Let us start importing the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Statistics\n",
    "using BlindedChallenge\n",
    "#using JSON3\n",
    "using Plots, LinearAlgebra, BenchmarkTools, Random\n",
    "using Base: @kwdef\n",
    "using BSON: @save\n",
    "using BSON: @load\n",
    "using BSON\n",
    "using LaTeXStrings\n",
    "using Distributions\n",
    "using SimpleChains\n",
    "using Static\n",
    "#using NPZ\n",
    "#using QuadGK\n",
    "#using StatsBase: sample, Weights\n",
    "using StatsPlots\n",
    "using ForwardDiff\n",
    "using LinearAlgebra\n",
    "using Statistics\n",
    "using ProgressMeter\n",
    "using Turing\n",
    "using Pathfinder\n",
    "using Optim\n",
    "using Transducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise\n",
    "using Effort"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: let us decide if we are going to use lagrangian or optimal resummation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resum = \"optimal\"\n",
    "if resum == \"lagrangian\"\n",
    "    println(\"You choose lagrangian resummation!\")\n",
    "elseif resum == \"optimal\"\n",
    "    println(\"You choose optimal resummation!\")\n",
    "else\n",
    "    error(\"You didn't choose a viable resummation!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale_cov = false\n",
    "if rescale_cov\n",
    "    println(\"You decided to rescale the covariance cov!\")\n",
    "    scaling_factor = 4\n",
    "    scaling_name = \"_scaled_\"\n",
    "else\n",
    "    println(\"You decided not to rescale the covariance!\")\n",
    "    scaling_factor = 1\n",
    "    scaling_name = \"\"\n",
    "end;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the trained Effort emulators for the blinded challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resum == \"lagrangian\"\n",
    "    println(\"You choose lagrangian resummation!\")\n",
    "    Mono_Emu = BSON.load(\"/home/marcobonici/Desktop/CosmologicalEmulators/trained_emulators/trained_effort_emulators/blinded_challenge/PyBird_061_10000_lagrangian_guido_spectra_check/emulator_PyBird_w0wanucdm_monopole.bson\")[:Pℓ]\n",
    "    Quad_Emu = BSON.load(\"/home/marcobonici/Desktop/CosmologicalEmulators/trained_emulators/trained_effort_emulators/blinded_challenge/PyBird_061_10000_lagrangian_guido_spectra_check/emulator_PyBird_w0wanucdm_quadrupole.bson\")[:Pℓ];\n",
    "elseif resum == \"optimal\"\n",
    "    println(\"You choose optimal resummation!\")\n",
    "    Mono_Emu = BSON.load(\"/home/marcobonici/Desktop/CosmologicalEmulators/trained_emulators/trained_effort_emulators/blinded_challenge/PyBird_061_10000_optiresum_final/emulator_PyBird_w0wanucdm_monopole.bson\")[:Pℓ]\n",
    "    Quad_Emu = BSON.load(\"/home/marcobonici/Desktop/CosmologicalEmulators/trained_emulators/trained_effort_emulators/blinded_challenge/PyBird_061_10000_optiresum_final/emulator_PyBird_w0wanucdm_quadrupole.bson\")[:Pℓ];\n",
    "else\n",
    "    error(\"You didn't choose a viable resummation!\")\n",
    "end;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function theory(θ, n, Mono_Emu, Quad_Emu)\n",
    "    # θ[1:3] cosmoparams, ln_10_As, H0, ΩM\n",
    "    # θ[4:9] bias\n",
    "    # θ[10:11] stoch\n",
    "    #f = fN(θ[3], 0.61)\n",
    "    f = Effort._f_z(0.61, θ[3], -1., 0.);\n",
    "    #conversion from c2-c4 to b2-b4\n",
    "    b2 = (θ[5]+θ[7])/√2\n",
    "    b4 = (θ[5]-θ[7])/√2\n",
    "    my_θ = deepcopy(θ)\n",
    "    my_θ[8] /= (0.7^2)\n",
    "    my_θ[9] /= (0.7^2)\n",
    "    n_bar = 3e-4 #value  that has been suggested by Guido himself\n",
    "    k_bins = Effort.create_bin_edges(BlindedChallenge.k_grid)\n",
    "    #stoch_0, stoch_2 = Effort.get_stoch_terms(0, θ[10], θ[11], n_bar, k_grid)\n",
    "    stoch_0, stoch_2 = Effort.get_stoch_terms_binned_efficient(0., my_θ[10], my_θ[11], n_bar, k_bins)\n",
    "    return vcat((Effort.get_Pℓ(my_θ[1:3], vcat(my_θ[4], b2, my_θ[6], b4, my_θ[8:9] , 0), f, Mono_Emu) .+ stoch_0)[1:n],\n",
    "                (Effort.get_Pℓ(my_θ[1:3], vcat(my_θ[4], b2, my_θ[6], b4, my_θ[8:9] , 0), f, Quad_Emu) .+ stoch_2)[1:n])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@benchmark theory(ones(11), 20, Mono_Emu, Quad_Emu)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turing & Pathfinder\n",
    "\n",
    "We are now ready to write our loglikelihood!\n",
    "We are going to employ Turing.jl, a Probabilistic Programming Language (PPL) written in Julia.\n",
    "Our model can be conveniently written using the `@model` macro.\n",
    "It is quite easy to write the priors with this formalism. The priors employed in this analysis are the same used by Guido in its analysis\n",
    "- $b_1$ $\\sim$ $\\mathrm{Uniform}$ $(0, 4)$\n",
    "- $c_2$ $\\sim$ $\\mathrm{Uniform}$ $(-4, 4)$\n",
    "- $b_3$ $\\sim$ $\\mathcal{N}(0,10)$ \n",
    "- $c_4$ $\\sim$ $\\mathcal{N}(0,2)$\n",
    "- $c_\\mathrm{ct}$ $\\sim$ $\\mathcal{N}(0,4)$\n",
    "- $c_\\mathrm{r1}$ $\\sim$ $\\mathcal{N}(0,8)$\n",
    "- $c_{\\epsilon,m}$ $\\sim$ $\\mathcal{N}(0,2)$\n",
    "- $c_{\\epsilon,q}$ $\\sim$ $\\mathcal{N}(0,4)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function pplmodel(data, cov, n, Mono_Emu, Quad_Emu)\n",
    "    ln10As ~ Uniform(2.9, 3.15)\n",
    "    H0     ~ Uniform(62.,68.)\n",
    "    ΩM     ~ Uniform(0.30, 0.34)\n",
    "    b1     ~ Uniform(0., 4.)\n",
    "    c2     ~ Uniform(-4., 4.)\n",
    "    b3     ~ Normal(0., 10.)\n",
    "    c4     ~ Normal(0., 2.)\n",
    "    cct    ~ Normal(0., 4.)\n",
    "    cr1    ~ Normal(0., 8.)\n",
    "    cϵm    ~ Normal(0., 2.)\n",
    "    cϵq    ~ Normal(0., 4.)\n",
    "\n",
    "    θ = [ln10As, H0, ΩM, b1, c2, b3, c4, cct, cr1, cϵm, cϵq]\n",
    "\n",
    "    prediction = theory(θ, n, Mono_Emu, Quad_Emu)\n",
    "\n",
    "    data ~ MvNormal(prediction, cov)\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "n = 20\n",
    "\n",
    "data_20, k_20, cov_20, yerror_Mono_20, yerror_Quad_20 = BlindedChallenge.create_data(n)\n",
    "\n",
    "model_20 = pplmodel(data_20, cov_20.*scaling_factor, 20, Mono_Emu, Quad_Emu);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_multi_20 = multipathfinder(model_20, 1000; nruns = 8, executor = Transducers.PreferParallel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps  = 1000\n",
    "nadapts = 250\n",
    "nchains = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params_20 = collect.(eachrow(result_multi_20.draws_transformed.value[1:nchains, :, 1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chains_20 = sample(model_20, Turing.NUTS(nadapts, 0.65), MCMCThreads(), nsteps, nchains; init_params = init_params_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = plot(chains_20)\n",
    "savefig(\"chains_turing_\"*resum*scaling_name*\"_Pathfinder_20.pdf\")\n",
    "savefig(\"chains_turing_\"*resum*scaling_name*\"_Pathfinder_20.png\")\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EFfort_env nt8 1.8.5",
   "language": "julia",
   "name": "effort_env-nt8-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
